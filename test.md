Yes, the script can be adapted to work with CSV files instead of Excel. The process is very similar, but instead of using the `openpyxl` library and `pd.read_excel()`, we will use `pd.read_csv()` to read and write CSV files. The rest of the logic remains largely the same.

Hereâ€™s the updated version of the script that works with CSV files:

### Full Python Script for CSV

```python
import pandas as pd
import requests
import json

# Load test cases from CSV file
file_path = 'test_cases.csv'  # CSV file with test cases
df = pd.read_csv(file_path)

# Function to send API request and return response
def send_api_request(input_data, headers):
    url = "https://10.155.111.59:38443/dgb-gateway/DCBK/AZRemrvices/1.0/remittance/TTRPY/bank-to-bank"
    
    # Send POST request with headers and data
    response = requests.post(url, headers=headers, data=json.dumps(input_data), verify=False)  # verify=False to ignore SSL verification
    return response

# Function to process each test case
def process_test_case(row):
    # Parse input data from the CSV file (Input Data column should be a JSON string)
    input_data = json.loads(row['Input Data'])
    
    # Define headers with Authorization, Content-Type, and x-api-key
    headers = {
        'Authorization': 'Bearer <your_auth_token>',  # Replace with your actual auth token
        'Content-Type': 'application/json',           # Set content type to JSON
        'x-api-key': '<your_api_key>'                 # Replace with your actual API key
    }

    # Send API request
    response = send_api_request(input_data, headers)
    
    # Handle the response (you can customize this based on your actual API response)
    try:
        # Assuming the response is in JSON format
        response_data = response.json()  
    except ValueError:
        response_data = {"error": "Invalid JSON response"}

    # For example, we compare the "status" field in the response with the expected result
    actual_result = response_data.get('status', 'Unknown')  # Modify this depending on your actual response structure
    
    # Update Execution Status based on comparison
    if row['Expected Results'] in actual_result:
        row['Execution Status'] = 'Passed'
        row['Actual Results'] = actual_result
        row['Bug Severity'] = 'N/A'
        row['Bug Priority'] = 'N/A'
    else:
        row['Execution Status'] = 'Failed'
        row['Actual Results'] = actual_result
        row['Bug Severity'] = 'High'
        row['Bug Priority'] = 'High'

    return row

# Apply the function to process all test cases
df = df.apply(process_test_case, axis=1)

# Write the updated DataFrame to a new CSV file
df.to_csv('test_cases_with_results.csv', index=False)

print("Test cases processed and results written to 'test_cases_with_results.csv'.")
```

### Key Changes for CSV:

1. **Reading CSV Files**:
   - Use `pd.read_csv(file_path)` to load the test cases from the CSV file.

   ```python
   df = pd.read_csv(file_path)
   ```

2. **Writing CSV Files**:
   - Use `df.to_csv('test_cases_with_results.csv', index=False)` to write the results to a new CSV file.

   ```python
   df.to_csv('test_cases_with_results.csv', index=False)
   ```

### Sample Input (CSV File):

The structure of the input CSV file (`test_cases.csv`) should look like this:

| Test Case ID | Preconditions | Input Data | Expected Results | Actual Results | Test Environment | Execution Status | Bug Severity | Bug Priority | Attachments | Notes |
|--------------|---------------|------------|------------------|-----------------|------------------|------------------|--------------|--------------|-------------|-------|
| TC001        | API Available | {"request_identifier": {...}, "request_data": {...}} | Success | Pending | Development | Pending | N/A | N/A | N/A | N/A |
| TC002        | API Available | {"request_identifier": {...}, "request_data": {...}} | Error | Pending | Development | Pending | High | High | N/A | N/A |

- **Input Data**: A string in JSON format representing the request body.
- **Expected Results**: The expected result that you anticipate from the API response.

### Execution Flow:

1. **The Script Reads the CSV**: The script will read the test cases from the `test_cases.csv` file.
2. **It Sends API Requests**: For each test case, the script sends an API request with the necessary headers and the data from the `Input Data` column.
3. **It Compares the Actual Result**: The script compares the actual API response with the `Expected Results` column.
4. **It Updates the Status**: The script updates the `Execution Status`, `Actual Results`, `Bug Severity`, and `Bug Priority` columns based on whether the test passes or fails.
5. **It Writes Results to a New CSV File**: Finally, the script writes the results to a new CSV file called `test_cases_with_results.csv`.

### Running the Script:

1. **Install Required Libraries** (if not already installed):

```bash
pip install pandas requests
```

2. **Run the Script**:

```bash
python test_api.py
```

3. **Output**: After running the script, the test results will be written to a new CSV file (`test_cases_with_results.csv`).

### Sample Output CSV:

| Test Case ID | Preconditions | Input Data | Expected Results | Actual Results | Test Environment | Execution Status | Bug Severity | Bug Priority | Attachments | Notes |
|--------------|---------------|------------|------------------|-----------------|------------------|------------------|--------------|--------------|-------------|-------|
| TC001        | API Available | {...}      | Success          | Success         | Development      | Passed           | N/A          | N/A          | N/A         | N/A   |
| TC002        | API Available | {...}      | Error            | Error Message   | Development      | Failed           | High         | High         | N/A         | N/A   |

This will give you the results of the tests in the `test_cases_with_results.csv` file, with the execution status and other details filled in.

### Conclusion:
This version of the script works with CSV files instead of Excel. It still reads the test cases, sends API requests, and writes the results back into a new CSV file. The core logic for sending requests, handling responses, and updating the results remains the same as before.
